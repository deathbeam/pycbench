#!/usr/bin/env python

import json
import os
import re
import subprocess
import sys
from argparse import ArgumentParser
import colorlog
import logging

handler = colorlog.StreamHandler()
handler.setFormatter(colorlog.ColoredFormatter("%(log_color)s%(levelname)-8s %(message)s"))
logger = colorlog.getLogger('pycbench')
logger.setLevel(logging.DEBUG)
logger.addHandler(handler)

basedir = os.path.dirname(os.path.realpath(__file__))

def runCbench(throughput, controller, port, millis,
        loops, switches, macs, warmup, delay):
    args = [
        os.path.realpath(basedir + "/oflops/cbench/cbench"),
        "-c", controller,
        "-p", str(port),
        "-m", str(millis),
        "-l", str(loops),
        "-s", str(switches),
        "-M", str(macs),
        "-w", str(warmup),
        "-D", str(delay)
        ]

    if throughput: args.append("-t")
    

    configuration = {
        'mode': 'througput' if throughput else 'latency',
        'controller': controller + ':' + str(port),
        'switches': switches,
        'macs': macs,
        'loops': loops,
        'warmup': warmup,
        'millis': millis,
        'delay': delay
        }

    try:
        logger.debug("Running CBench test. Please wait...")
        configuration['result'] = subprocess.check_output(args, stderr=subprocess.PIPE)
    except subprocess.CalledProcessError as e:
        logger.error(e)
        dumpJson(configuration, "stdout")
        sys.exit(1)

def formatResult(output):
    cbenchText = output['result']
    total = re.search('RESULT:[^=]+= ([0-9./]+)', cbenchText).group(1).split('/')
    runs = re.findall('total = ([0-9.]+)', cbenchText)

    output['result'] = {
        'runs': [float(run) * 1000 for run in runs],
        'min': float(total[0]),
        'max': float(total[1]),
        'avg': float(total[2]),
        'stdev': float(total[3])
        }

    return output

def mergeResults(cbenchData, outputFile):
    result = []

    if outputFile != "stdout" and os.path.isfile(outputFile):
        with open(outputFile, 'r') as contentFile:
            result = json.load(contentFile)

    result.append(cbenchData)
    return result

def format_json(jsonDict):
    return json.dumps(
            jsonDict,
            sort_keys=True,
            indent=4,
            separators=(',', ': '))

def dumpJson(jsonResult, outputFile):
    result = format_json(jsonResult)

    if outputFile == "stdout":
        print(result)
    else:
        with open(outputFile, 'w') as contentFile:
            outputFile.write(result)

def run():
    # Create argument parser
    parser = ArgumentParser()

    # Add parser arguments
    parser.add_argument('-t', '--throughput',
                        action='store_true',
                        help='Test throughput instead of latency')

    parser.add_argument('-c', '--controller',
                        nargs='?', const="127.0.0.1", type=str,
                        help='IP address of OpenFlow controller (127.0.0.1)')

    parser.add_argument('-p', '--port',
                        nargs='?', const=6633, type=int,
                        help='Port of OpenFlow controller (default: 6633)')

    parser.add_argument('-d', '--delay',
                        nargs='?', const=0, type=int,
                        help='Delay starting testing after FEATURES_REPLY (0)')

    parser.add_argument('-m', '--millis',
                        nargs='?', const=10000, type=int,
                        help='Test length in milliseconds (10000)')

    parser.add_argument('-l', '--loops',
                        nargs='?', const=10, type=int,
                        help='Loops per test (10)')

    parser.add_argument('-s', '--switches',
                        nargs='?', const=10, type=int,
                        help='Number of emulated switches (16)')

    parser.add_argument('-M', '--macs',
                        nargs='?', const=100, type=int,
                        help='Number of MAC addresses per switch (100)')

    parser.add_argument('-w', '--warmup',
                        nargs='?', const=1, type=int,
                        help='Number of warmup runs before actual test, first one is ignored (1)')

    parser.add_argument('-o', '--output',
                        nargs='?', const="stdout", type=str,
                        help='Place to store the result (stdout)')

    # Parse arguments from command line
    a = parser.parse_args()

    # If no arguments passed, set the default values
    if a.controller == None: a.controller = "127.0.0.1"
    if a.port == None:       a.port = 6633
    if a.millis == None:     a.millis = 10000
    if a.loops == None:      a.loops = 10
    if a.switches == None:   a.switches = 10
    if a.macs == None:       a.macs = 100
    if a.warmup == None:     a.warmup = 1
    if a.output == None:     a.output = "stdout"
    if a.delay == None:      a.delay = 0

    cBenchResult = runCbench(
            throughput=a.throughput,
            controller=a.controller,
            port=a.port,
            millis=a.millis,
            loops=a.loops,
            switches=a.switches,
            macs=a.macs,
            warmup=a.warmup,
            delay=a.delay)

    formatedResult = formatResult(cBenchResult)
    mergedResults = mergeResults(formatedResult, a.output)
    dumpJson(mergedResults, a.output)

if __name__ == '__main__':
    run()
